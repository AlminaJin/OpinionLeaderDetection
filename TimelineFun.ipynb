{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "\n",
    "\n",
    "# To set your environment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "def auth():\n",
    "    return '<your_bearer_token>'\n",
    "\n",
    "def create_url(user_id):\n",
    "    # Replace with user ID below\n",
    "    # user_id = 14499829\n",
    "    return \"https://api.twitter.com/2/users/{}/tweets\".format(user_id)\n",
    "\n",
    "\n",
    "def get_params(start_time, end_time):\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "\n",
    "    return {\"tweet.fields\": \"created_at\", \"max_results\": 100,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time}\n",
    "            # \"start_time\": \"2021-11-01T00:00:00Z\",\n",
    "            # \"end_time\": \"2021-12-01T00:00:00Z\"}\n",
    "\n",
    "\n",
    "def get_new_params(new_token, start_time, end_time):\n",
    "    return {\"tweet.fields\": \"created_at\", \"max_results\": 100,\n",
    "            'pagination_token': new_token,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time}\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tweet(id, start_time, end_time):\n",
    "    timelineDataList = []\n",
    "    bearer_token = auth()\n",
    "    url = create_url(id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    params = get_params(start_time,end_time)\n",
    "    time.sleep(5)\n",
    "    json_response = connect_to_endpoint(url, headers, params)\n",
    "    # print(json_response)\n",
    "    if 'data' in json_response.keys():\n",
    "        timelineDataList = json_response['data']\n",
    "    if 'meta' in json_response.keys():\n",
    "        while 'next_token' in json_response['meta']:\n",
    "            new_params = get_new_params(json_response['meta']['next_token'], start_time, end_time)\n",
    "            time.sleep(5)\n",
    "            json_response = connect_to_endpoint(url,headers, new_params)\n",
    "            if 'data' in json_response.keys():\n",
    "                timelineDataList = timelineDataList+json_response['data']\n",
    "    return timelineDataList\n",
    "\n",
    "\n",
    "def filter_tweet(json_response):\n",
    "    keylist = set('omicron coronavirus koronavirus covid corona isolation quarantine cdc wuhancoronavirus wuhanlockdown ncov wuhan N95 kungflu epidemic outbreak sinophobia'.split())\n",
    "    timelineDataList = []\n",
    "    for i in json_response:\n",
    "        if i['text'][0:2] == 'RT':\n",
    "            pass\n",
    "        for j in keylist:\n",
    "            if j in i['text'].lower():\n",
    "                timelineDataList.append(i['text'].lower())\n",
    "                break\n",
    "    return timelineDataList\n",
    "\n",
    "\n",
    "def sentence_transformer(tweets):\n",
    "    wv = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    wholevec = []\n",
    "    for i in tweets:\n",
    "        vec = wv.encode(i)\n",
    "        wholevec.append(vec)\n",
    "    return wholevec\n",
    "\n",
    "\n",
    "def ave(wordveclist):\n",
    "    n = len(wordveclist[0])\n",
    "    avevec = [0]*n\n",
    "    for i in wordveclist:\n",
    "        for j in range(n):\n",
    "            avevec[j] += i[j]\n",
    "    for i in range(n):\n",
    "        avevec[i] = avevec[i]/n\n",
    "    return avevec\n",
    "\n",
    "def similarity(vec1, vec2):\n",
    "    result = spatial.distance.cosine(vec1, vec2)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def availableTweetToVec(idlist, initial_time, num_timestep):\n",
    "    vec = []\n",
    "    for id in idlist:\n",
    "        time.sleep(5)\n",
    "        filtedveclist = []\n",
    "        for i in range(num_timestep):\n",
    "            start_time = initial_time + relativedelta(days=i*10)\n",
    "            end_time = start_time + relativedelta(days=10)\n",
    "            unfilterTweet = get_tweet(id, start_time.isoformat(\"T\") + \"Z\", end_time.isoformat(\"T\") + \"Z\")\n",
    "            tweet = filter_tweet(unfilterTweet)\n",
    "#             print(len(tweet))\n",
    "            filtedveclist.append(ave(sentence_transformer(tweet)))\n",
    "#             print(len(filtedveclist))\n",
    "        vec.append(filtedveclist)\n",
    "#         print(len(vec))\n",
    "    return vec\n",
    "\n",
    "def filteravailable(idlist, initial_time, num_timestep):\n",
    "    unavailableid = []\n",
    "    for id in idlist:\n",
    "        time.sleep(5)\n",
    "        for i in range(num_timestep):\n",
    "            # start_time = \"2021-{:02d}-01T00:00:00Z\".format(9+i)\n",
    "            # end_time = \"2021-{:02d}-01T00:00:00Z\".format(10+i)\n",
    "            start_time = initial_time + relativedelta(days=i*10)\n",
    "#             timedelta(month=i)\n",
    "            end_time = start_time + relativedelta(days=10)\n",
    "#     timedelta(month=1)\n",
    "            unfilterTweet = get_tweet(id, start_time.isoformat(\"T\") + \"Z\", end_time.isoformat(\"T\") + \"Z\")\n",
    "            tweet = filter_tweet(unfilterTweet)\n",
    "            if len(tweet) == 0:\n",
    "                unavailableid.append(id)\n",
    "                print(len(unavailableid))\n",
    "                break\n",
    "    availableid = []\n",
    "    for i in idlist:\n",
    "        if i not in unavailableid:\n",
    "            availableid.append(i)\n",
    "    return availableid\n",
    "\n",
    "def generateAvailableFollowing(idlist):\n",
    "    for i in idlist:\n",
    "        id_file = Path(i)\n",
    "        gzip_path = id_file.with_suffix('.p')\n",
    "        if gzip_path.is_file():\n",
    "            print('skipping file already exists: {}'.format(gzip_path))\n",
    "            continue\n",
    "        following = get_following(i, 20)\n",
    "        available_user = filteravailable(following,datetime(2021,9,1),10)\n",
    "        print(len(available_user))\n",
    "        pickle.dump(available_user, open(gzip_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def availableTweet(idlist, initial_time, num_timestep, len_timestep):\n",
    "    idtonum = {}\n",
    "    for id in idlist:\n",
    "        id_file = Path('pfile/'+str(initial_time)+str(len_timestep)+'timeline'+id)\n",
    "        gzip_path = id_file.with_suffix('.p')\n",
    "        if gzip_path.is_file():\n",
    "            print('skipping file already exists: {}'.format(gzip_path))\n",
    "            continue\n",
    "        time.sleep(5)\n",
    "        all_num = []\n",
    "        filter_num = []\n",
    "        all_unfilterTweet = []\n",
    "        all_tweet = []\n",
    "        for i in range(num_timestep):\n",
    "            start_time = initial_time + relativedelta(days=i*len_timestep)\n",
    "            end_time = start_time + relativedelta(days=len_timestep)\n",
    "            unfilterTweet = get_tweet(id, start_time.isoformat(\"T\") + \"Z\", end_time.isoformat(\"T\") + \"Z\")\n",
    "            all_unfilterTweet.append(unfilterTweet)\n",
    "            all_num.append(len(unfilterTweet))\n",
    "            tweet = filter_tweet(unfilterTweet)\n",
    "            all_tweet.append(tweet)\n",
    "            filter_num.append(len(tweet))\n",
    "        idtonum[id] = [all_num,filter_num]\n",
    "        pickle.dump([all_unfilterTweet, all_tweet], open(gzip_path, \"wb\"))\n",
    "    return idtonum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(2020,3,1)\n",
    "checkId = pickle.load(open(\"pfile/checkId.p\", \"rb\"))\n",
    "result = availableTweet(checkId,start_time, 70,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idtonum = {}\n",
    "for id in checkId:\n",
    "    id_file = Path('pfile/timeline'+id)\n",
    "    gzip_path = id_file.with_suffix('.p')\n",
    "    if gzip_path.is_file():\n",
    "        file = pickle.load(open(gzip_path, \"rb\"))\n",
    "        all_num = []\n",
    "        filter_num = []\n",
    "        for i in range(len(file[0])):\n",
    "            all_num.append(len(file[0][i]))\n",
    "            filter_num.append(len(file[1][i]))\n",
    "        idtonum[id] = [all_num,filter_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCount(idDict, num_timestep, len_timestep):    \n",
    "    all_num_list = []\n",
    "    filter_num_list = []\n",
    "    zero_count_list = []\n",
    "    filter_zero_count = []\n",
    "    for id in idtonum.keys():\n",
    "        for i in range(len(idtonum[id][0])):\n",
    "            all_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
